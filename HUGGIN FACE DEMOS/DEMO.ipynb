{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3adce32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOKENIZATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ceb9e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import TFAutoModel\n",
    "from transformers import TFAutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6865249",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "checkpoint = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "text = [\n",
    "    'this is a simple text', \n",
    "    'i ate short text'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "293fbef7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(2, 7), dtype=int32, numpy=\n",
       "array([[ 101, 2023, 2003, 1037, 3722, 3793,  102],\n",
       "       [ 101, 1045, 8823, 2460, 3793,  102,    0]])>, 'attention_mask': <tf.Tensor: shape=(2, 7), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 0]])>}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = tokenizer(text , padding=True, truncation=True , return_tensors='tf')\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "251103ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20fbf3ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 7), dtype=int32, numpy=\n",
       "array([[ 101, 2023, 2003, 1037, 3722, 3793,  102],\n",
       "       [ 101, 1045, 2293, 2460, 3793,  102,    0]])>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af1c0492",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 7), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 0]])>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9863335",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fecfb32c9854cf1a7d64b74d74a6037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/256M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english were not used when initializing TFDistilBertModel: ['pre_classifier', 'classifier', 'dropout_19']\n",
      "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFAutoModel.from_pretrained('distilbert-base-uncased-finetuned-sst-2-english')\n",
    "output = model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b356f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 7, 768), dtype=float32, numpy=\n",
       "array([[[ 0.3320293 ,  0.02742751,  0.18346703, ...,  0.31159946,\n",
       "          0.6723575 ,  0.36877427],\n",
       "        [ 0.4239502 ,  0.27092987, -0.07830648, ...,  0.08568719,\n",
       "          0.5814348 ,  0.5713896 ],\n",
       "        [ 0.29482278,  0.13571008,  0.04054649, ...,  0.16526826,\n",
       "          0.52327955,  0.6798635 ],\n",
       "        ...,\n",
       "        [ 0.43496478,  0.14738175,  0.05489651, ...,  0.2700857 ,\n",
       "          0.4811685 ,  0.47562525],\n",
       "        [ 0.43679562,  0.20165877,  0.11719923, ...,  0.36819005,\n",
       "          0.4024661 ,  0.4030651 ],\n",
       "        [ 0.94820166,  0.05986686,  0.5224403 , ...,  0.7581328 ,\n",
       "          0.16098009, -0.30662575]],\n",
       "\n",
       "       [[ 0.2352387 , -0.15724163,  0.10453077, ...,  0.287233  ,\n",
       "          0.9235809 , -0.16500083],\n",
       "        [ 0.672294  ,  0.09057958, -0.20700504, ...,  0.25807652,\n",
       "          0.961981  , -0.16170302],\n",
       "        [ 0.6843438 ,  0.34063095,  0.50549793, ...,  0.14057136,\n",
       "          0.7961355 , -0.04010963],\n",
       "        ...,\n",
       "        [ 0.22571935, -0.04144791,  0.18887624, ...,  0.24607223,\n",
       "          0.27786902,  0.03735432],\n",
       "        [ 1.036884  ,  0.09212299,  0.30490473, ...,  0.57681096,\n",
       "          0.49532026, -0.60975623],\n",
       "        [ 0.0453649 , -0.2835694 , -0.10165996, ...,  0.38202935,\n",
       "          0.61261064, -0.00950256]]], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['last_hidden_state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb08f6d6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english were not used when initializing TFDistilBertForSequenceClassification: ['dropout_19']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english and are newly initialized: ['dropout_38']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model2 = TFAutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased-finetuned-sst-2-english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e8c76b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output2 = model2(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2aeb3b2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[-3.1598666,  3.2557592],\n",
       "       [ 2.7002509, -2.3572714]], dtype=float32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2['logits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9ba564f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[0.00163312, 0.9983669 ],\n",
       "       [0.993679  , 0.00632109]], dtype=float32)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "predict = tf.math.softmax(output2.logits , axis=1)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "50cf616d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'NEGATIVE', 1: 'POSITIVE'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "413c3ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(2, 7), dtype=int32, numpy=\n",
       "array([[ 101, 2023, 2003, 1037, 3722, 3793,  102],\n",
       "       [ 101, 1045, 8823, 2460, 3793,  102,    0]])>, 'token_type_ids': <tf.Tensor: shape=(2, 7), dtype=int32, numpy=\n",
       "array([[0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0]])>, 'attention_mask': <tf.Tensor: shape=(2, 7), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 0]])>}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "text = [\n",
    "    'this is a simple text', \n",
    "    'i ate short text'\n",
    "]\n",
    "\n",
    "\n",
    "input = tokenizer(text, padding=True, truncation=True, return_tensors='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "273fabce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2023, 2003, 1037, 3722, 3793, 2075, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer('this is a simple texting')\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d2c8226",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2023, 2003, 1037, 3722, 3793, 2075]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1c1898a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2023, 2003, 1037, 3722, 3793, 2075, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " model_token = tokenizer.prepare_for_model(input_ids)\n",
    "model_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "824601d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] this is a simple texting [SEP]'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(model_token['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2372195e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2023, 2003, 1037, 3722, 3793], [1045, 8823, 2460, 3793]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batching muultiple tex together \n",
    "\n",
    "tokens = [tokenizer.tokenize(t) for t in text]\n",
    "ids = [tokenizer.convert_tokens_to_ids(tok) for tok in tokens]\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf3e7878",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5), dtype=int32, numpy=array([[2023, 2003, 1037, 3722, 3793]])>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id1 = tf.constant([ids[0]])\n",
    "id1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1ccf87ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4), dtype=int32, numpy=array([[1045, 8823, 2460, 3793]])>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2 = tf.constant([ids[1]])\n",
    "id2\n",
    "# id2(tokenizer.pad_token_id) * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ed61271d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "tokenizer.pad_token_id\n",
    "# input_ids = tf.constant([ids])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
