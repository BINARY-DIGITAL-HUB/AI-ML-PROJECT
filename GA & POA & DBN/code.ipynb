{
 "cells": [
  {
   "cell_type": "raw",
   "id": "83d540b8-c126-48ec-9b52-282324563446",
   "metadata": {},
   "source": [
    "🔥 Hybrid GA + PSO for DBN Training Optimization\n",
    "This approach optimizes hyperparameters dynamically while training.\n",
    "\n",
    "🛠️ Steps\n",
    "GA selects optimal architecture (number of layers & neurons).\n",
    "PSO fine-tunes training parameters (learning rate, batch size).\n",
    "Train DBN with the best configuration."
   ]
  },
  {
   "cell_type": "raw",
   "id": "5c1b9293-259b-4989-bc1c-3de09e4b8396",
   "metadata": {},
   "source": [
    "🔹 Explanation\n",
    "✅ GA selects the best architecture (number of layers & neurons).\n",
    "✅ PSO fine-tunes training hyperparameters (learning rate, batch size).\n",
    "✅ The final DBN trains using the optimized settings.\n",
    "\n",
    "🔥 Hybrid GA + PSO for Pre-training Optimization\n",
    "This approach searches for the best hyperparameters before training.\n",
    "\n",
    "🛠️ Steps\n",
    "GA optimizes structural parameters (hidden layers, neurons).\n",
    "PSO optimizes learning parameters (learning rate, batch size).\n",
    "Train the DBN using the best hyperparameters found.\n",
    "🔹 The difference is that GA and PSO run together before training. The training only starts after the best parameters are selected.\n",
    "\n",
    "🚀 Which Hybrid Approach is Best?\n",
    "Approach\tUse Case\n",
    "During Training (Dynamic)\tIf hyperparameters need adaptation while training\n",
    "Before Training (Pre-training)\tIf you want optimal parameters before training\n",
    "Let me know if you want a combined GA+PSO framework! 🚀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c77ff8-8fc0-40e2-9205-5faf23869adc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d7492b4-30e3-4e24-9303-d3c2f731d83c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dbn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyswarm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pso\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdbn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SupervisedDBNClassification\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mnist\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Load dataset\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dbn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pygad\n",
    "from pyswarm import pso\n",
    "from sklearn.metrics import accuracy_score\n",
    "from dbn.tensorflow import SupervisedDBNClassification\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(x_train.shape[0], -1) / 255.0\n",
    "x_test = x_test.reshape(x_test.shape[0], -1) / 255.0\n",
    "\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fc9327-6ddb-4747-82c8-a4eb54cecc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# -------- Step 1: GA for Finding the Best DBN Architecture -------- #\n",
    "def ga_fitness(solution, solution_idx):\n",
    "    num_layers = int(solution[0])\n",
    "    neurons_per_layer = int(solution[1])\n",
    "\n",
    "    num_layers = max(1, min(5, num_layers))\n",
    "    neurons_per_layer = max(10, min(500, neurons_per_layer))\n",
    "\n",
    "    return num_layers, neurons_per_layer  # Return best architecture\n",
    "\n",
    "ga_instance = pygad.GA(\n",
    "    num_generations=5, num_parents_mating=3,\n",
    "    fitness_func=ga_fitness, sol_per_pop=6,\n",
    "    num_genes=2, init_range_low=1, init_range_high=500, gene_type=int\n",
    ")\n",
    "ga_instance.run()\n",
    "best_architecture, _, _ = ga_instance.best_solution()\n",
    "\n",
    "best_layers = int(best_architecture[0])\n",
    "best_neurons = int(best_architecture[1])\n",
    "print(f\"Best DBN Architecture: {best_layers} layers, {best_neurons} neurons per layer\")\n",
    "\n",
    "# -------- Step 2: PSO for Fine-Tuning Training Parameters -------- #\n",
    "def pso_fitness(params):\n",
    "    learning_rate, batch_size = params\n",
    "    learning_rate = max(0.0001, min(0.1, learning_rate))  # Limit learning rate range\n",
    "    batch_size = max(16, min(128, int(batch_size)))  # Limit batch size range\n",
    "\n",
    "    dbn = SupervisedDBNClassification(\n",
    "        hidden_layers_structure=[best_neurons] * best_layers,\n",
    "        learning_rate=learning_rate, batch_size=batch_size,\n",
    "        n_epochs_rbm=10, n_iter_backprop=50, verbose=False\n",
    "    )\n",
    "\n",
    "    dbn.fit(x_train, y_train)\n",
    "    y_pred = dbn.predict(x_test)\n",
    "    return -accuracy_score(y_test, y_pred)  # PSO minimizes, so return negative accuracy\n",
    "\n",
    "best_params, _ = pso(pso_fitness, [0.0001, 16], [0.1, 128])\n",
    "best_lr, best_batch = best_params\n",
    "print(f\"Best Training Parameters: Learning Rate={best_lr}, Batch Size={int(best_batch)}\")\n",
    "\n",
    "# -------- Step 3: Train Final DBN with Optimized Parameters -------- #\n",
    "final_dbn = SupervisedDBNClassification(\n",
    "    hidden_layers_structure=[best_neurons] * best_layers,\n",
    "    learning_rate=best_lr, batch_size=int(best_batch),\n",
    "    n_epochs_rbm=10, n_iter_backprop=50, verbose=True\n",
    ")\n",
    "\n",
    "final_dbn.fit(x_train, y_train)\n",
    "y_final_pred = final_dbn.predict(x_test)\n",
    "final_accuracy = accuracy_score(y_test, y_final_pred)\n",
    "\n",
    "print(f\"Final DBN Accuracy: {final_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ab3db9-24a2-481f-863d-69eb49886752",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a2d8dd1-ca2f-4415-9747-653599b00d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDATE CODE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f099f594-d423-46db-bff8-5c42f9129dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution - (c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -upyterlab (c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "ERROR: Could not find a version that satisfies the requirement deep-belief-network (from versions: none)\n",
      "ERROR: No matching distribution found for deep-belief-network\n"
     ]
    }
   ],
   "source": [
    "!pip install deep-belief-network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c411aba-7dd5-4af3-b652-88dcfa3edaca",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'deepbeliefnetwork'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeepbeliefnetwork\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SupervisedDBNClassification\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyswarm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pso  \u001b[38;5;66;03m# Install with `pip install pyswarm`\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'deepbeliefnetwork'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pygad\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from deepbeliefnetwork import SupervisedDBNClassification\n",
    "from pyswarm import pso  # Install with `pip install pyswarm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee7f5555-af5b-470e-8ac8-9540f8155cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+git://github.com/albertbup/deep-belief-network.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f867814a-4ec2-4298-9986-bee51e67c994",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# -------- Step 1: Load & Preprocess Data -------- #\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "# Load dataset (modify with your dataset)\n",
    "data = load_digits()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# -------- Step 2: GA for Finding the Best DBN Architecture -------- #\n",
    "def ga_fitness(solution, solution_idx):\n",
    "    num_layers = int(solution[0])\n",
    "    neurons_per_layer = int(solution[1])\n",
    "\n",
    "    num_layers = max(1, min(5, num_layers))  # Limit layers (1-5)\n",
    "    neurons_per_layer = max(10, min(500, neurons_per_layer))  # Limit neurons (10-500)\n",
    "\n",
    "    return num_layers, neurons_per_layer  # Return best architecture\n",
    "\n",
    "ga_instance = pygad.GA(\n",
    "    num_generations=5, num_parents_mating=3,\n",
    "    fitness_func=ga_fitness, sol_per_pop=6,\n",
    "    num_genes=2, init_range_low=1, init_range_high=500, gene_type=int\n",
    ")\n",
    "\n",
    "ga_instance.run()\n",
    "best_architecture, _, _ = ga_instance.best_solution()\n",
    "\n",
    "best_layers = int(best_architecture[0])\n",
    "best_neurons = int(best_architecture[1])\n",
    "print(f\"Best DBN Architecture: {best_layers} layers, {best_neurons} neurons per layer\")\n",
    "\n",
    "# -------- Step 3: PSO for Fine-Tuning Training Parameters -------- #\n",
    "def pso_fitness(params):\n",
    "    learning_rate, batch_size = params\n",
    "    learning_rate = max(0.0001, min(0.1, learning_rate))  # Limit learning rate range\n",
    "    batch_size = max(16, min(128, int(batch_size)))  # Limit batch size range\n",
    "\n",
    "    dbn = SupervisedDBNClassification(\n",
    "        hidden_layers_structure=[best_neurons] * best_layers,\n",
    "        learning_rate=learning_rate, batch_size=batch_size,\n",
    "        n_epochs_rbm=10, n_iter_backprop=50, verbose=False\n",
    "    )\n",
    "\n",
    "    dbn.fit(x_train, y_train)\n",
    "    y_pred = dbn.predict(x_test)\n",
    "    return -accuracy_score(y_test, y_pred)  # PSO minimizes, so return negative accuracy\n",
    "\n",
    "best_params, _ = pso(pso_fitness, [0.0001, 16], [0.1, 128])\n",
    "best_lr, best_batch = best_params\n",
    "print(f\"Best Training Parameters: Learning Rate={best_lr}, Batch Size={int(best_batch)}\")\n",
    "\n",
    "# -------- Step 4: Train Final DBN with Optimized Parameters -------- #\n",
    "final_dbn = SupervisedDBNClassification(\n",
    "    hidden_layers_structure=[best_neurons] * best_layers,\n",
    "    learning_rate=best_lr, batch_size=int(best_batch),\n",
    "    n_epochs_rbm=10, n_iter_backprop=50, verbose=True\n",
    ")\n",
    "\n",
    "final_dbn.fit(x_train, y_train)\n",
    "y_final_pred = final_dbn.predict(x_test)\n",
    "final_accuracy = accuracy_score(y_test, y_final_pred)\n",
    "\n",
    "print(f\"Final DBN Accuracy: {final_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce4501e6-0a77-4a43-8c4c-d9fe3018d03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.datasets import fetch_openml\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.neural_network import BernoulliRBM\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# # Load the dataset\n",
    "# mnist = fetch_openml('mnist_784', version=1)\n",
    "# X, y = mnist['data'], mnist['target']\n",
    "\n",
    "# # Split the dataset into training and test sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Preprocess the data by scaling it\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# # Initialize the RBM model\n",
    "# rbm = BernoulliRBM(n_components=256, learning_rate=0.01, n_iter=20, verbose=1)\n",
    "# # Initialize the logistic regression model\n",
    "# logistic = LogisticRegression(max_iter=1000)\n",
    "# # Create a pipeline that first extracts features using the RBM and then classifies with logistic regression\n",
    "# dbn_pipeline = Pipeline(steps=[('rbm', rbm), ('logistic', logistic)])\n",
    "# # Train the DBN\n",
    "# dbn_pipeline.fit(X_train_scaled, y_train)\n",
    "\n",
    "# # Evaluate the model on the test set\n",
    "# dbn_score = dbn_pipeline.score(X_test_scaled, y_test)\n",
    "# print(f'DBN Classification score: {dbn_score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e57d90d-ece9-44f2-9950-ea14dd66c6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ee921df-1f91-4a7b-b62d-796dd5ba335e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d37ffa7-fdc0-4a8a-b613-92f8a07d0ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
       "0         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "69995     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "69996     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "69997     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "69998     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "69999     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "       pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "1          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "2          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "3          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "4          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "...        ...  ...       ...       ...       ...       ...       ...   \n",
       "69995      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "69996      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "69997      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "69998      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "69999      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0           0.0       0.0       0.0       0.0       0.0  \n",
       "1           0.0       0.0       0.0       0.0       0.0  \n",
       "2           0.0       0.0       0.0       0.0       0.0  \n",
       "3           0.0       0.0       0.0       0.0       0.0  \n",
       "4           0.0       0.0       0.0       0.0       0.0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "69995       0.0       0.0       0.0       0.0       0.0  \n",
       "69996       0.0       0.0       0.0       0.0       0.0  \n",
       "69997       0.0       0.0       0.0       0.0       0.0  \n",
       "69998       0.0       0.0       0.0       0.0       0.0  \n",
       "69999       0.0       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[70000 rows x 784 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
