{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdfc75ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasetNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading dataset-1.5.2-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (4.64.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.5.1)\n",
      "Collecting sqlalchemy>=1.3.2\n",
      "  Downloading SQLAlchemy-1.4.45-cp39-cp39-win_amd64.whl (1.6 MB)\n",
      "     ---------------------------------------- 1.6/1.6 MB 1.7 MB/s eta 0:00:00\n",
      "Collecting banal>=1.0.1\n",
      "  Downloading banal-1.0.6-py2.py3-none-any.whl (6.1 kB)\n",
      "Collecting alembic>=0.6.2\n",
      "  Downloading alembic-1.9.1-py3-none-any.whl (210 kB)\n",
      "     -------------------------------------- 210.4/210.4 kB 3.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm) (0.3.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (1.23.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2022.6)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.7/78.7 kB 4.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sqlalchemy>=1.3.2->dataset) (2.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from Mako->alembic>=0.6.2->dataset) (2.1.1)\n",
      "Installing collected packages: banal, sqlalchemy, Mako, alembic, dataset\n",
      "Successfully installed Mako-1.2.4 alembic-1.9.1 banal-1.0.6 dataset-1.5.2 sqlalchemy-1.4.45\n"
     ]
    }
   ],
   "source": [
    "pip install dataset tqdm pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20d79941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasetsNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading datasets-2.8.0-py3-none-any.whl (452 kB)\n",
      "     ------------------------------------ 452.9/452.9 kB 726.9 kB/s eta 0:00:00\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (2.28.1)\n",
      "Collecting dill<0.3.7\n",
      "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "     ------------------------------------ 110.5/110.5 kB 802.2 kB/s eta 0:00:00\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n",
      "     -------------------------------------- 132.9/132.9 kB 4.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (1.23.4)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (10.0.1)\n",
      "Collecting fsspec[http]>=2021.11.1\n",
      "  Downloading fsspec-2022.11.0-py3-none-any.whl (139 kB)\n",
      "     -------------------------------------- 139.5/139.5 kB 1.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pandas in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (1.5.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (0.11.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (4.64.1)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.3-cp39-cp39-win_amd64.whl (323 kB)\n",
      "     -------------------------------------- 323.5/323.5 kB 1.4 MB/s eta 0:00:00\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.1.0-cp39-cp39-win_amd64.whl (30 kB)\n",
      "Collecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.8.2-cp39-cp39-win_amd64.whl (56 kB)\n",
      "     ---------------------------------------- 56.8/56.8 kB 3.1 MB/s eta 0:00:00\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp39-cp39-win_amd64.whl (28 kB)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (2.1.1)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.3-cp39-cp39-win_amd64.whl (34 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.3.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->datasets) (2022.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: xxhash, multidict, fsspec, frozenlist, dill, async-timeout, yarl, responses, multiprocess, aiosignal, aiohttp, datasets\n",
      "Successfully installed aiohttp-3.8.3 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.8.0 dill-0.3.6 frozenlist-1.3.3 fsspec-2022.11.0 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.1.0 yarl-1.8.2\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12c275e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a7b7ae6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98e48748fffa40beb4e55a275ddfa3b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/7.44k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cba4b5536d4f4b4783e55976ee290a32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/201k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d01f3d19f3da4af3b16be69db4fb09cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/36.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset tapaco/en to C:/Users/HP/.cache/huggingface/datasets/tapaco/en/1.0.0/71d200534b520a174927a8f0479c06220a0a6fb5201a84ebfce19006c6354698...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab49e36b6c2d44bb8788a052d70b677b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67daf60a5ea745c2a0cbd398baad549d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/32.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9def8ce9fad14028ad0d865f793248cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/158053 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset tapaco downloaded and prepared to C:/Users/HP/.cache/huggingface/datasets/tapaco/en/1.0.0/71d200534b520a174927a8f0479c06220a0a6fb5201a84ebfce19006c6354698. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98294ff26ef84495ac1fd2cf4806ebeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Loading dataset\n",
    "dataset = load_dataset('tapaco', 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8990dba5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['paraphrase_set_id', 'sentence_id', 'paraphrase', 'lists', 'tags', 'language'],\n",
       "        num_rows: 158053\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a4a2c89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e06694c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['paraphrase_set_id', 'sentence_id', 'paraphrase', 'lists', 'tags', 'language'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a2267311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I ate the cheese.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]['paraphrase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1035c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conting loaded data and saveing into local repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18b8f8f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 158053/158053 [00:17<00:00, 8814.51it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>lists</th>\n",
       "      <th>paraphrase</th>\n",
       "      <th>paraphrase_set_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>416554</td>\n",
       "      <td>I ate the cheese.</td>\n",
       "      <td>[907, 4000, 6677, 7361, 7415]</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2481696</td>\n",
       "      <td>I eat cheese.</td>\n",
       "      <td>[907]</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2721028</td>\n",
       "      <td>I'm eating a yogurt.</td>\n",
       "      <td>[992, 3800]</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3010891</td>\n",
       "      <td>I'm eating cheese.</td>\n",
       "      <td>[6905]</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4129977</td>\n",
       "      <td>I'm having some cheese.</td>\n",
       "      <td>[6905]</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language    lists               paraphrase              paraphrase_set_id  \\\n",
       "0        1   416554        I ate the cheese.  [907, 4000, 6677, 7361, 7415]   \n",
       "1        1  2481696            I eat cheese.                          [907]   \n",
       "2        1  2721028     I'm eating a yogurt.                    [992, 3800]   \n",
       "3        1  3010891       I'm eating cheese.                         [6905]   \n",
       "4        1  4129977  I'm having some cheese.                         [6905]   \n",
       "\n",
       "  sentence_id tags  \n",
       "0          []   en  \n",
       "1          []   en  \n",
       "2          []   en  \n",
       "3          []   en  \n",
       "4          []   en  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_tapaco_dataset(dataset, out_file):\n",
    "    tapaco = []\n",
    "    # The dataset has only train split.\n",
    "    for data in tqdm(dataset[\"train\"]):\n",
    "        keys = data.keys()\n",
    "        tapaco.append([data[key] for key in keys])\n",
    "    tapaco_df = pd.DataFrame(\n",
    "        data=tapaco,\n",
    "        columns=[\n",
    "            \"language\",\n",
    "            \"lists\",\n",
    "            \"paraphrase\",\n",
    "            \"paraphrase_set_id\",\n",
    "            \"sentence_id\",\n",
    "            \"tags\",\n",
    "        ],\n",
    "    )\n",
    "    tapaco_df.to_csv(out_file, sep=\"\\t\", index=None)\n",
    "    return tapaco_df\n",
    "\n",
    "tapaco_df = process_tapaco_dataset(dataset,\"tapaco_huggingface.csv\")\n",
    "tapaco_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf45f988",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158053, 6)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tapaco_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "04fde0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1                              [907]\n",
      "3                             [6905]\n",
      "4                             [6905]\n",
      "6                  [907, 4000, 7415]\n",
      "8      [907, 4000, 7360, 7389, 7409]\n",
      "                   ...              \n",
      "495                [907, 4000, 7412]\n",
      "496                [907, 4000, 7412]\n",
      "497                [907, 4000, 7412]\n",
      "498                            [956]\n",
      "499                           [6905]\n",
      "Name: paraphrase_set_id, Length: 392, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def generate_tapaco_paraphrase_dataset(dataset, out_file):\n",
    "    dataset_df = dataset[[\"paraphrase\", \"paraphrase_set_id\"]]\n",
    "    non_single_labels = (\n",
    "        dataset_df[\"paraphrase_set_id\"]\n",
    "        .value_counts()[dataset_df[\"paraphrase_set_id\"].value_counts() > 1]\n",
    "        .index.tolist()\n",
    "    )\n",
    "    tapaco_df_sorted = dataset_df.loc[\n",
    "        dataset_df[\"paraphrase_set_id\"].isin(non_single_labels)\n",
    "    ]\n",
    "    tapaco_paraphrases_dataset = []\n",
    "\n",
    "    for paraphrase_set_id in tqdm(tapaco_df_sorted[\"paraphrase_set_id\"].unique()):\n",
    "        id_wise_paraphrases = tapaco_df_sorted[\n",
    "            tapaco_df_sorted[\"paraphrase_set_id\"] == paraphrase_set_id\n",
    "        ]\n",
    "        len_id_wise_paraphrases = (\n",
    "            id_wise_paraphrases.shape[0]\n",
    "            if id_wise_paraphrases.shape[0] % 2 == 0\n",
    "            else id_wise_paraphrases.shape[0] - 1\n",
    "        )\n",
    "        for ix in range(0, len_id_wise_paraphrases, 2):\n",
    "            current_phrase = id_wise_paraphrases.iloc[ix][0]\n",
    "            for count_ix in range(ix + 1, ix + 2):\n",
    "                next_phrase = id_wise_paraphrases.iloc[ix + 1][0]\n",
    "                tapaco_paraphrases_dataset.append([current_phrase, next_phrase])\n",
    "    tapaco_paraphrases_dataset_df = pd.DataFrame(\n",
    "        tapaco_paraphrases_dataset, columns=[\"Text\", \"Paraphrase\"]\n",
    "    )\n",
    "    tapaco_paraphrases_dataset_df.to_csv(out_file, sep=\"\\t\", index=None)\n",
    "    return tapaco_paraphrases_dataset_df\n",
    "\n",
    "tapaco_paraphrases_dataset_df = generate_tapaco_paraphrase_dataset(tapaco_df,\"tapaco_paraphrases_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd4e3760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Paraphrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I ate the cheese.</td>\n",
       "      <td>I eat cheese.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm eating a yogurt.</td>\n",
       "      <td>I'm eating cheese.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm having some cheese.</td>\n",
       "      <td>I eat some cheese.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's Monday.</td>\n",
       "      <td>It is Monday today.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It's Monday today.</td>\n",
       "      <td>Today is Monday.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Text           Paraphrase\n",
       "0        I ate the cheese.        I eat cheese.\n",
       "1     I'm eating a yogurt.   I'm eating cheese.\n",
       "2  I'm having some cheese.   I eat some cheese.\n",
       "3             It's Monday.  It is Monday today.\n",
       "4       It's Monday today.     Today is Monday."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset_df = pd.read_csv(\"tapaco_paraphrases_dataset.csv\",sep=\"\\t\")\n",
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f38318",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4172bcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "      <th>prefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I ate the cheese.</td>\n",
       "      <td>I eat cheese.</td>\n",
       "      <td>paraphrase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm eating a yogurt.</td>\n",
       "      <td>I'm eating cheese.</td>\n",
       "      <td>paraphrase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm having some cheese.</td>\n",
       "      <td>I eat some cheese.</td>\n",
       "      <td>paraphrase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's Monday.</td>\n",
       "      <td>It is Monday today.</td>\n",
       "      <td>paraphrase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It's Monday today.</td>\n",
       "      <td>Today is Monday.</td>\n",
       "      <td>paraphrase</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                input_text          target_text      prefix\n",
       "0        I ate the cheese.        I eat cheese.  paraphrase\n",
       "1     I'm eating a yogurt.   I'm eating cheese.  paraphrase\n",
       "2  I'm having some cheese.   I eat some cheese.  paraphrase\n",
       "3             It's Monday.  It is Monday today.  paraphrase\n",
       "4       It's Monday today.     Today is Monday.  paraphrase"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Renaming the columns\n",
    "dataset_df.columns = [\"input_text\",\"target_text\"]\n",
    "# Adding a prefix. Here we shall keep \"paraphrase\" as a prefix.\n",
    "dataset_df[\"prefix\"] = \"paraphrase\"\n",
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16917ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data,test_data = train_test_split(dataset_df,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f364eecc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "      <th>prefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6766</th>\n",
       "      <td>I'll call at your house tomorrow.</td>\n",
       "      <td>Goodbye. See you tomorrow.</td>\n",
       "      <td>paraphrase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15902</th>\n",
       "      <td>Maybe next time.</td>\n",
       "      <td>Some other time perhaps.</td>\n",
       "      <td>paraphrase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56334</th>\n",
       "      <td>He often adopts the behaviours and speech patt...</td>\n",
       "      <td>He often adopts the behaviors and speech patte...</td>\n",
       "      <td>paraphrase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57850</th>\n",
       "      <td>They look worried.</td>\n",
       "      <td>They seem worried.</td>\n",
       "      <td>paraphrase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44766</th>\n",
       "      <td>The surgery went well.</td>\n",
       "      <td>The operation was successful.</td>\n",
       "      <td>paraphrase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>You need to exercise more.</td>\n",
       "      <td>You must study harder.</td>\n",
       "      <td>paraphrase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25048</th>\n",
       "      <td>Tom climbed out the window.</td>\n",
       "      <td>Tom crawled out of the window.</td>\n",
       "      <td>paraphrase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62587</th>\n",
       "      <td>Let's check with him.</td>\n",
       "      <td>Let's check with her.</td>\n",
       "      <td>paraphrase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21537</th>\n",
       "      <td>Tom is a native French speaker.</td>\n",
       "      <td>French is Tom's primary language.</td>\n",
       "      <td>paraphrase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67309</th>\n",
       "      <td>Tom gathered his children around him.</td>\n",
       "      <td>Tom gathered his kids around him.</td>\n",
       "      <td>paraphrase</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66166 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              input_text  \\\n",
       "6766                   I'll call at your house tomorrow.   \n",
       "15902                                   Maybe next time.   \n",
       "56334  He often adopts the behaviours and speech patt...   \n",
       "57850                                 They look worried.   \n",
       "44766                             The surgery went well.   \n",
       "...                                                  ...   \n",
       "1902                          You need to exercise more.   \n",
       "25048                        Tom climbed out the window.   \n",
       "62587                              Let's check with him.   \n",
       "21537                    Tom is a native French speaker.   \n",
       "67309              Tom gathered his children around him.   \n",
       "\n",
       "                                             target_text      prefix  \n",
       "6766                          Goodbye. See you tomorrow.  paraphrase  \n",
       "15902                           Some other time perhaps.  paraphrase  \n",
       "56334  He often adopts the behaviors and speech patte...  paraphrase  \n",
       "57850                                 They seem worried.  paraphrase  \n",
       "44766                      The operation was successful.  paraphrase  \n",
       "...                                                  ...         ...  \n",
       "1902                              You must study harder.  paraphrase  \n",
       "25048                     Tom crawled out of the window.  paraphrase  \n",
       "62587                              Let's check with her.  paraphrase  \n",
       "21537                  French is Tom's primary language.  paraphrase  \n",
       "67309                  Tom gathered his kids around him.  paraphrase  \n",
       "\n",
       "[66166 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2b5bde4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "      <th>prefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43568</th>\n",
       "      <td>Your ideas are rather old-fashioned.</td>\n",
       "      <td>His ideas are a little archaic.</td>\n",
       "      <td>paraphrase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47880</th>\n",
       "      <td>Tom told me he was going to talk to Mary.</td>\n",
       "      <td>Tom told me he'd talk to Mary.</td>\n",
       "      <td>paraphrase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Today is a warm day.</td>\n",
       "      <td>Today is a very hot day.</td>\n",
       "      <td>paraphrase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34324</th>\n",
       "      <td>She felt faint at the sight of blood.</td>\n",
       "      <td>She fainted when she saw blood.</td>\n",
       "      <td>paraphrase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2201</th>\n",
       "      <td>Fill out this form, please.</td>\n",
       "      <td>Will you fill out this form, please?</td>\n",
       "      <td>paraphrase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25438</th>\n",
       "      <td>They drink coke.</td>\n",
       "      <td>They drink cola.</td>\n",
       "      <td>paraphrase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59363</th>\n",
       "      <td>Tom and I were both invited.</td>\n",
       "      <td>Both Tom and I were invited.</td>\n",
       "      <td>paraphrase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10241</th>\n",
       "      <td>Do you want fruit juice?</td>\n",
       "      <td>Do you want some fruit juice?</td>\n",
       "      <td>paraphrase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72752</th>\n",
       "      <td>They say that they're sleepy.</td>\n",
       "      <td>They say they're sleepy.</td>\n",
       "      <td>paraphrase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54813</th>\n",
       "      <td>Tom and Mary have just gotten married.</td>\n",
       "      <td>Tom and Mary just got married.</td>\n",
       "      <td>paraphrase</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7352 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      input_text  \\\n",
       "43568       Your ideas are rather old-fashioned.   \n",
       "47880  Tom told me he was going to talk to Mary.   \n",
       "200                         Today is a warm day.   \n",
       "34324      She felt faint at the sight of blood.   \n",
       "2201                 Fill out this form, please.   \n",
       "...                                          ...   \n",
       "25438                           They drink coke.   \n",
       "59363               Tom and I were both invited.   \n",
       "10241                   Do you want fruit juice?   \n",
       "72752              They say that they're sleepy.   \n",
       "54813     Tom and Mary have just gotten married.   \n",
       "\n",
       "                                target_text      prefix  \n",
       "43568       His ideas are a little archaic.  paraphrase  \n",
       "47880        Tom told me he'd talk to Mary.  paraphrase  \n",
       "200                Today is a very hot day.  paraphrase  \n",
       "34324       She fainted when she saw blood.  paraphrase  \n",
       "2201   Will you fill out this form, please?  paraphrase  \n",
       "...                                     ...         ...  \n",
       "25438                      They drink cola.  paraphrase  \n",
       "59363          Both Tom and I were invited.  paraphrase  \n",
       "10241         Do you want some fruit juice?  paraphrase  \n",
       "72752              They say they're sleepy.  paraphrase  \n",
       "54813        Tom and Mary just got married.  paraphrase  \n",
       "\n",
       "[7352 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "652cff29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install simpletransformers\n",
    "# pip install torch\n",
    "# pip install transformers[torch]==4.\n",
    "from simpletransformers.t5 import T5Model\n",
    "from tensorflow import keras\n",
    "\n",
    "args = {\n",
    "    \"reprocess_input_data\": True,\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"max_seq_length\": 256,\n",
    "    \"num_train_epochs\": 4,\n",
    "    \"num_beams\": None,\n",
    "    \"do_sample\": True,\n",
    "    \"top_k\": 50,\n",
    "    \"top_p\": 0.95,\n",
    "    \"use_multiprocessing\": False,\n",
    "    \"save_steps\": -1,\n",
    "    \"save_eval_checkpoints\": True,\n",
    "    \"evaluate_during_training\": False,\n",
    "    \"adam_epsilon\": 1e-08,\n",
    "    \"eval_batch_size\": 6,\n",
    "    \"fp_16\": False,\n",
    "    \"gradient_accumulation_steps\": 16,\n",
    "    \"learning_rate\": 0.0003,\n",
    "    \"max_grad_norm\": 1.0,\n",
    "    \"n_gpu\": 1,\n",
    "    \"seed\": 42,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4316589",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b637d67a22a3457d9b8355299e7073ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca4a5eeb272145acba8b596424fe5e7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/231M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "944964e15758456aab842f399af83ae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/773k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f1e3a5e588a4886891716c4da7c6d77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.32M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = T5Model(\"t5\",\"t5-small\", args=args, use_cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f9d75fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66607b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01e04c24aa0b4b11aadfdafb0c495e16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3478: FutureWarning: \n",
      "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
      "`__call__` method to prepare your inputs and the tokenizer under the `as_target_tokenizer` context manager to prepare\n",
      "your targets.\n",
      "\n",
      "Here is a short example:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, ...)\n",
      "with tokenizer.as_target_tokenizer():\n",
      "    labels = tokenizer(tgt_texts, ...)\n",
      "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
      "\n",
      "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
      "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
      "\n",
      "  warnings.warn(formatted_warning, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd9a5f16f04d4a49a06fbfac090dca89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80f850c9a88a4f3f81833abd425cb87f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 4:   0%|          | 0/8271 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "model.train_model(train_data, eval_data=test_data, use_cuda=False,acc=sklearn.metrics.accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c02bb730",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.t5 import T5Model\n",
    "import os\n",
    "root_dir = os.getcwd()\n",
    "trained_model_path = os.path.join(root_dir,\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bda6334c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.t5 import T5Model\n",
    "import os\n",
    "# trained_model_path = os.path.join(root_dir,\"outputs\")\n",
    "args = {\n",
    "\"overwrite_output_dir\": True,\n",
    "\"max_seq_length\": 256,\n",
    "\"max_length\": 50,\n",
    "\"top_k\": 50,\n",
    "\"top_p\": 0.95,\n",
    "\"num_return_sequences\": 5\n",
    "}\n",
    "trained_model_path =  'MODEL/checkpoint-2064-epoch-4'\n",
    "trained_model = T5Model(\"t5\",trained_model_path,args=args, use_cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "18ecbc08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1eff103c78444a7b65fd1f04e954493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating outputs:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9c790444ebb4e5ab50e12ff2280b7a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Decoding outputs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paraphrased\n",
      "['In the African folktales, the stories reflect the culture where diverse types of animals abound.', 'In African folktales, stories reveal the culture where a lot of animals can survive.', 'In Africa, stories are a symbol of culture where diversity of animals exists.', 'These stories reflect the culture of where diverse types of animals exist.', 'In the African folktales, stories reflect culture in which many species of animals abound abound; and there exists a lot of cultural diversity in the region.']\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "prefix = \"paraphrase\"\n",
    "pred = trained_model.predict([f\"{prefix}: In the African folktales, the stories reflect the culture where diverse types of animals abound\"])\n",
    "\n",
    "print('Paraphrased')\n",
    "print(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d7f5ee00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the African folktales, the stories reflect the culture where diverse types of animals abound.\n",
      "In African folktales, stories reveal the culture where a lot of animals can survive.\n",
      "In Africa, stories are a symbol of culture where diversity of animals exists.\n",
      "These stories reflect the culture of where diverse types of animals exist.\n",
      "In the African folktales, stories reflect culture in which many species of animals abound abound; and there exists a lot of cultural diversity in the region.\n"
     ]
    }
   ],
   "source": [
    "for p in pred[0]: \n",
    "    print(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
