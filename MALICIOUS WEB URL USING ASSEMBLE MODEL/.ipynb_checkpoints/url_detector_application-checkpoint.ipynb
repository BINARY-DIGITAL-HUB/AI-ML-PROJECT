{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a31d41d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = 'https://www.collinsdictionary.com/dictionary/english/game'\n",
    "data2 = 'http://www.garage-pirenne.be/index.php?option=com_content&view=article&id=70&vsig70_0=15'\n",
    "data3 = \"https://www.google.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3bd9c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove WWW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09864a91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71083b1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top level doamin :  com\n",
      "sub domain :  www\n",
      "top level domain :  com\n",
      "full (fld) domain :  collinsdictionary.com\n",
      "pase url :  SplitResult(scheme='https', netloc='www.collinsdictionary.com', path='/dictionary/english/game', query='', fragment='')\n"
     ]
    }
   ],
   "source": [
    "# EXTRACT URL lenght\n",
    "from tld import get_tld\n",
    "\n",
    "url_obj = get_tld(data1, fail_silently=True, as_object=True, fix_protocol=True)\n",
    "print('top level doamin : ' , url_obj) # top level domain\n",
    "print('sub domain : ' , url_obj.subdomain) # sub level domain\n",
    "print('top level domain : ' , url_obj.tld) # sub level domain\n",
    "print('full (fld) domain : ' , url_obj.fld) # sub level domain\n",
    "print('pase url : ' , url_obj.parsed_url) # sub level domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a255b630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_obj.parsed_url.scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2f88cf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'www.collinsdictionary.com'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get gull URL address.......\n",
    "full_domain = url_obj.parsed_url.netloc\n",
    "get_domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "8ac00ff7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE DATA : http://www.garage-pirenne.be/index.php?option=com_content&view=article&id=70&vsig70_0=15\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urlparse\n",
    "import re\n",
    "from tld import get_tld\n",
    "import joblib\n",
    "\n",
    "data = data2\n",
    "\n",
    "# FEATURE TO EXTRACT == # url_len , abnormal_url, https, digits, leters, shortining_service, havin_ip, \n",
    "\n",
    "class URLExtractFeatures:\n",
    "    print('THE DATA :', data)\n",
    "\n",
    "    \n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.url_lenght = len(data)\n",
    "        print('url lenght : ' , url_lenght)\n",
    "\n",
    "   \n",
    "\n",
    "    def normal_url(self, url):\n",
    "        hostname = urlparse(url).hostname\n",
    "        hostname = str(hostname)\n",
    "        match = re.search(hostname, url)\n",
    "        if match:\n",
    "            # print match.group()\n",
    "            return 1\n",
    "        else:\n",
    "            # print 'No matching pattern found'\n",
    "            # print(f'Abnormal  URL: {url}   ===================   HOSTNAME: {hostname}')\n",
    "            return 0\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # checking for shortening services \n",
    "    def shortining_Service(self, url):\n",
    "        match = re.search('bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|'\n",
    "                          'yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|'\n",
    "                          'short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|'\n",
    "                          'doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|'\n",
    "                          'db\\.tt|qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|'\n",
    "                          'q\\.gs|is\\.gd|po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|'\n",
    "                          'x\\.co|prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|'\n",
    "                          'tr\\.im|link\\.zip\\.net',\n",
    "                          url)\n",
    "        if match:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "\n",
    "    def having_ip_address(self, url):\n",
    "        match = re.search(\n",
    "            '(([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.'\n",
    "            '([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\/)|'  # IPv4\n",
    "            '(([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.'\n",
    "            '([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\/)|'  # IPv4 with port\n",
    "            '((0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\/)' # IPv4 in hexadecimal\n",
    "            '(?:[a-fA-F0-9]{1,4}:){7}[a-fA-F0-9]{1,4}|'\n",
    "            '([0-9]+(?:\\.[0-9]+){3}:[0-9]+)|'\n",
    "            '((?:(?:\\d|[01]?\\d\\d|2[0-4]\\d|25[0-5])\\.){3}(?:25[0-5]|2[0-4]\\d|[01]?\\d\\d|\\d)(?:\\/\\d{1,2})?)', url)  # Ipv6\n",
    "        if match:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    \n",
    "    \n",
    "    def get_features(self):\n",
    "        \n",
    "         # removing www.... \n",
    "        remove_www = data.replace('www.', '')\n",
    "        remove_www\n",
    "\n",
    "        # ectracting symbols features\n",
    "        feature = ['@','?','-','=','.','#','%','+','$','!','*',',','//']\n",
    "\n",
    "        symbol_feature = []\n",
    "        for a in feature:\n",
    "            symbol_feature.append(remove_www.count(a))\n",
    "        \n",
    "        print('symbol feature ', symbol_feature)\n",
    "            \n",
    "        #checking url if normal or not         \n",
    "        norm_url =  self.normal_url(data)\n",
    "        print('normal url : ' , bool(norm_url) , norm_url)\n",
    "        \n",
    "         # extracting http or https features\n",
    "        http_secure = 1 if str(urlparse(data).scheme)=='https' else 0\n",
    "        print('http or https : ' , bool(http_secure))\n",
    "\n",
    "        # extracting digit count \n",
    "        digit_count = len([d for d in data if d.isnumeric()])\n",
    "        print('digit_count = ' , digit_count)\n",
    "\n",
    "        # extracting letter count \n",
    "        alpha_count = len([d for d in data if d.isalpha()])\n",
    "        print('alpha_count = ' , alpha_count)\n",
    "        \n",
    "        short_service = self.shortining_Service(data)\n",
    "        print('short_service =', bool(short_service))\n",
    "        \n",
    "        having_ip = self.having_ip_address(data)\n",
    "        print(\"having_ip = \", bool(having_ip))\n",
    "            \n",
    "        # list variable to hold url extracted features\n",
    "        features_holder = []\n",
    "        features_holder.append(url_lenght)\n",
    "        [features_holder.append(f) for f in symbol_feature]\n",
    "        features_holder.append(norm_url)\n",
    "        features_holder.append(http_secure)\n",
    "        features_holder.append(digit_count)\n",
    "        features_holder.append(alpha_count)\n",
    "        features_holder.append(short_service)\n",
    "        features_holder.append(having_ip)\n",
    "        \n",
    "        return features_holder\n",
    "    \n",
    "\n",
    "class Predictor: \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def load_model(self , model):\n",
    "        self.models = [joblib.load(m) for m in model]\n",
    "        print('models : ' , self.models)\n",
    "        \n",
    "    def essemble_prediction(self, data):\n",
    "        prediction= []\n",
    "        prediction = [model.predict([data])[0] for model in self.models]\n",
    "        final_pre = np.bincount(prediction).argmax()\n",
    "        print(prediction)\n",
    "        print('final prediction : = ' , final_pre)\n",
    "        return final_pre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "93ff672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def essemble_predictions(models, data):\n",
    "    \n",
    "    prediction = [model.predict(data) for model in models]\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "85b69d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[88, 0, 1, 1, 4, 2, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 7, 63, 0, 0]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "59834c0a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url lenght :  88\n",
      "symbol feature  [0, 1, 1, 4, 2, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "normal url :  True 1\n",
      "http or https :  False\n",
      "digit_count =  7\n",
      "alpha_count =  63\n",
      "short_service = False\n",
      "having_ip =  False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[88, 0, 1, 1, 4, 2, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 7, 63, 0, 0]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_feature = URLExtractFeatures(data)\n",
    "url_feature.get_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ae0c3fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "rf = joblib.load('url_classifier_randomforest_model.jb')\n",
    "sgd = joblib.load('url_SGD_model.jb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "dec1db88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def essemble_prediction(models, data):\n",
    "    prediction= []\n",
    "    prediction = [model.predict([data])[0] for model in models]\n",
    "    final_pre = np.bincount(prediction).argmax()\n",
    "    print(prediction)\n",
    "    print('final prediction : = ' , final_prediction)\n",
    "    return final_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "61c6afac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "f2ae5b71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "essemble_prediction([rf, sgd], features_holder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923c4bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predic = Predictor()\n",
    "models = ['url_classifier_randomforest_model.jb', 'url_SGD_model.jb']\n",
    "predic.load_model(models)\n",
    "predic.essemble_prediction(features_holder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7640c722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url_len , abnormal_url, https, digits, leters, shortining_service, havin_ip, "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
